{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "keras-lstm-text-gen.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Machine-Learning-Tokyo/tfjs-workshop/blob/master/char-rnn/keras_lstm_text_gen.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "VQfqqFL8pxHP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Build and train the LSTM.\n",
        "\n",
        "This script is copied from https://github.com/keras-team/keras/blob/master/examples/lstm_text_generation.py"
      ]
    },
    {
      "metadata": {
        "id": "VJw_TlmDo1_j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3619
        },
        "outputId": "5649940c-aa7c-4651-d465-700a6b41e5bb"
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "#Example script to generate text from Nietzsche's writings.\n",
        "At least 20 epochs are required before the generated text\n",
        "starts sounding coherent.\n",
        "It is recommended to run this script on GPU, as recurrent\n",
        "networks are quite computationally intensive.\n",
        "If you try this script on new data, make sure your corpus\n",
        "has at least ~100k characters. ~1M is better.\n",
        "'''\n",
        "\n",
        "from __future__ import print_function\n",
        "from keras.callbacks import LambdaCallback\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.utils.data_utils import get_file\n",
        "import numpy as np\n",
        "import random\n",
        "import sys\n",
        "import io\n",
        "\n",
        "path = get_file(\n",
        "    'nietzsche.txt',\n",
        "    origin='https://s3.amazonaws.com/text-datasets/nietzsche.txt')\n",
        "with io.open(path, encoding='utf-8') as f:\n",
        "    text = f.read().lower()\n",
        "print('corpus length:', len(text))\n",
        "\n",
        "chars = sorted(list(set(text)))\n",
        "print('total chars:', len(chars))\n",
        "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
        "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
        "\n",
        "# cut the text in semi-redundant sequences of maxlen characters\n",
        "maxlen = 40\n",
        "step = 3\n",
        "sentences = []\n",
        "next_chars = []\n",
        "for i in range(0, len(text) - maxlen, step):\n",
        "    sentences.append(text[i: i + maxlen])\n",
        "    next_chars.append(text[i + maxlen])\n",
        "print('nb sequences:', len(sentences))\n",
        "\n",
        "print('Vectorization...')\n",
        "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
        "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
        "for i, sentence in enumerate(sentences):\n",
        "    for t, char in enumerate(sentence):\n",
        "        x[i, t, char_indices[char]] = 1\n",
        "    y[i, char_indices[next_chars[i]]] = 1\n",
        "\n",
        "\n",
        "# build the model: a single LSTM\n",
        "print('Build model...')\n",
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
        "model.add(Dense(len(chars), activation='softmax'))\n",
        "\n",
        "optimizer = RMSprop(lr=0.01)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
        "\n",
        "\n",
        "def sample(preds, temperature=1.0):\n",
        "    # helper function to sample an index from a probability array\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)\n",
        "\n",
        "\n",
        "def on_epoch_end(epoch, _):\n",
        "    # Function invoked at end of each epoch. Prints generated text.\n",
        "    print()\n",
        "    print('----- Generating text after Epoch: %d' % epoch)\n",
        "\n",
        "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
        "    for diversity in [0.02, 0.04, 0.2, 0.5, 1.0, 1.2]:\n",
        "        print('----- diversity:', diversity)\n",
        "\n",
        "        generated = ''\n",
        "        sentence = text[start_index: start_index + maxlen]\n",
        "        generated += sentence\n",
        "        print('----- Generating with seed: \"' + sentence + '\"')\n",
        "        sys.stdout.write(generated)\n",
        "\n",
        "        for i in range(400):\n",
        "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
        "            for t, char in enumerate(sentence):\n",
        "                x_pred[0, t, char_indices[char]] = 1.\n",
        "\n",
        "            preds = model.predict(x_pred, verbose=0)[0]\n",
        "            next_index = sample(preds, diversity)\n",
        "            next_char = indices_char[next_index]\n",
        "\n",
        "            generated += next_char\n",
        "            sentence = sentence[1:] + next_char\n",
        "\n",
        "            sys.stdout.write(next_char)\n",
        "            sys.stdout.flush()\n",
        "        print()\n",
        "\n",
        "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n",
        "\n",
        "model.fit(x, y,\n",
        "          batch_size=128,\n",
        "          epochs=5,\n",
        "          callbacks=[print_callback])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "corpus length: 600893\n",
            "total chars: 57\n",
            "nb sequences: 200285\n",
            "Vectorization...\n",
            "Build model...\n",
            "Epoch 1/5\n",
            "200285/200285 [==============================] - 228s 1ms/step - loss: 1.9739\n",
            "\n",
            "----- Generating text after Epoch: 0\n",
            "----- diversity: 0.2\n",
            "----- Generating with seed: \"he very nature and being of the\n",
            "\"thing-i\"\n",
            "he very nature and being of the\n",
            "\"thing-interstance of the sense of the spectations and and the stands and all the spection of the such a surding and a conar and the sense and the sense of the sense and the sense and the sense and the conscience of the sense and the sense and all the sense and the sense and the sense and the spected and and the such and the sense and the courder to the constinction, and interpention of a sentices and int\n",
            "----- diversity: 0.5\n",
            "----- Generating with seed: \"he very nature and being of the\n",
            "\"thing-i\"\n",
            "he very nature and being of the\n",
            "\"thing-inced the possible to a some the the deed to the for the morality of he as nature and procise in the respossice morality of the still and a seet as the morality of the sonself and power, in the sacess and all as a sertice itself and poters and i the\n",
            "comations itself and in the spacies and surionatice of the is regaids to all the consequent of an a such and extrations and the same is we possible we \n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \"he very nature and being of the\n",
            "\"thing-i\"\n",
            "he very nature and being of the\n",
            "\"thing-ind, this kind, but the stanture! is advolachisnes truanias though notlings ichord words, wond, in reval leable ceeled, doon i make a in ygher couldining, elfor meansefsly of the pursualed sense\n",
            "it a allostrortams those  new be ofining and this was abi allow , bolkm.\n",
            "\n",
            "12j. it dread myspeck not tasurance and but whicl to ne diman be cans of bleast: to overananne-dury osty is the exprosed.inty; fut\n",
            "s\n",
            "----- diversity: 1.2\n",
            "----- Generating with seed: \"he very nature and being of the\n",
            "\"thing-i\"\n",
            "he very nature and being of the\n",
            "\"thing-ind ti\n",
            "wedten dat uuresticulest to down.\n",
            "\n",
            "\n",
            "\n",
            "c-tutiese, borjultent on iffucn edvent pryasess--but the thein interish-sa\n",
            "syme good a\n",
            "dinvidly to itsestougriesu witurilified menuaccio trucat hassostles, and pnounho riffore! belotifity\n",
            "maselled dountive; powarly feoflems vartarneunesny of\n",
            "man\n",
            "kilfto! we greenif itect pactare actifise3, ideatialy not necemicable, seets at a saints.--highe ple\"sed. the t\n",
            "Epoch 2/5\n",
            "200285/200285 [==============================] - 224s 1ms/step - loss: 1.6243\n",
            "\n",
            "----- Generating text after Epoch: 1\n",
            "----- diversity: 0.2\n",
            "----- Generating with seed: \" the romans, and, in all modesty be it a\"\n",
            " the romans, and, in all modesty be it and the subjection of the and indising the said of the sensual to a state of the explained to the subjectation of the subjection of the still a streat and as the soul promated the the still to the sensual to the fact of the state of the state and so the fact to the explained to the man the subjection of the strange of the explained the responsibility of the subjection of the one and as it is and en\n",
            "----- diversity: 0.5\n",
            "----- Generating with seed: \" the romans, and, in all modesty be it a\"\n",
            " the romans, and, in all modesty be it all the one in the hest been the conception, and in the viction of instinction of the instinction and as distrait of\n",
            "the sensipition. the stapperantly still believering that oneself in the extent of the in\n",
            "its ease and such morality and the one that all the so fact one, what is not indistraticial to the state is the can\n",
            "all the prisouration of the show dombit self and the sensibility of any prossia\n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \" the romans, and, in all modesty be it a\"\n",
            " the romans, and, in all modesty be it a loorrinm exise for. on all so finctansies, honeven the some itself\n",
            "thes ofgecces at nhition on the is ersanners and is becometing ham\n",
            "eventity.\n",
            "\n",
            "\n",
            "f exception of he have agreedd to diskalaed. their not ast incorporing lase we rather only the\n",
            "weaker thought of macking man intemptine,\n",
            "who more\n",
            "could it prthaused and strange it to other is as a blenexy. is\n",
            "mops\n",
            "any self-inawive, when noal fafther har\n",
            "----- diversity: 1.2\n",
            "----- Generating with seed: \" the romans, and, in all modesty be it a\"\n",
            " the romans, and, in all modesty be it ands sucha-sufficiated adring as tabitiones instanceion--fo; in thim. so flait. \"lift! for the that the mitroiogipaces.ope-morebly, sympate\n",
            "of wholl good\n",
            "that seegn a made flough,\n",
            "on the charst, a sumfails as gillent, but all news living just\n",
            "but men desireivedness.\n",
            "\"3chicantauy as act, all mian war eitny\n",
            "sad happine.--enougranised tinshmullitaclers with which\n",
            "weed onlyt exparients and ourseive\n",
            "mul\n",
            "Epoch 3/5\n",
            "200285/200285 [==============================] - 224s 1ms/step - loss: 1.5345\n",
            "\n",
            "----- Generating text after Epoch: 2\n",
            "----- diversity: 0.2\n",
            "----- Generating with seed: \"36\n",
            "\n",
            "=objection.=--or is there a counter-\"\n",
            "36\n",
            "\n",
            "=objection.=--or is there a counter--or and the conscience of the subtlers the transicism of the subtle and the face of the sense and a subtless, the same the philosopher of the sense of the procisted to every sense of the speak to be stand of the own will be the the sense of the such a stricks and the sense of the restrained to the procisted and and the sense of the sense that the subtle, and some the conscience the the the speak o\n",
            "----- diversity: 0.5\n",
            "----- Generating with seed: \"36\n",
            "\n",
            "=objection.=--or is there a counter-\"\n",
            "36\n",
            "\n",
            "=objection.=--or is there a counter-and the personal of the obe all the conscience of the plainting and seet and contrance of the restrait of the of the impersoned to doorroist, and procisted to call good of the strength to such schel and restroine of man of a strices of its desisted to means, for the recolom of means of the such an the problemed existed, occare the than the breat is most that he bad knowledged to be restrudume the \n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \"36\n",
            "\n",
            "=objection.=--or is there a counter-\"\n",
            "36\n",
            "\n",
            "=objection.=--or is there a counter--de there msen name,\n",
            "ameny fromg have the too\n",
            "thinken their\n",
            "filchten stand--in that a. finally general rests short, at with what itself-granar, the fir characterwariatical referising to look, and blo mical musiniar\n",
            "life, sumpails himself the \"man whatever, these can their so far\n",
            "and\n",
            "indief to others belietw, prystruinable dessiacly upon ever odver\n",
            "and an\n",
            "eured, come in these restined\n",
            "to young thos\n",
            "----- diversity: 1.2\n",
            "----- Generating with seed: \"36\n",
            "\n",
            "=objection.=--or is there a counter-\"\n",
            "36\n",
            "\n",
            "=objection.=--or is there a counter-brink\" on astigral in the uelouiaiar.\"\n",
            "is\n",
            "and e lofaning has have a akeod to going--is just, of ugrer.\n",
            "\n",
            "will inly those firm them jusoisie in the mobely and tranding is that has regard upon rerpooster, play gainer intelf,d,tht in assuice uspead to puiner a re; this philoserasly, and the hogriamm\n",
            "questiveal, if this spiritubly such are the\n",
            "elittlitesenm, and, urable pleasure himself but itsispots h\n",
            "Epoch 4/5\n",
            "200285/200285 [==============================] - 223s 1ms/step - loss: 1.4899\n",
            "\n",
            "----- Generating text after Epoch: 3\n",
            "----- diversity: 0.2\n",
            "----- Generating with seed: \"understand it, and laugh at the way\n",
            "in w\"\n",
            "understand it, and laugh at the way\n",
            "in which in the same in the same and as a sense, and the sense, and and and of the same and even in the standard and and and the considerations of the standard and and and and in the sense, and the same the consequently and as a standing in the sense, the power of the the portence, and the something in the the problem and and strength of the exception, and the sense, and and and who has the sense--and\n",
            "----- diversity: 0.5\n",
            "----- Generating with seed: \"understand it, and laugh at the way\n",
            "in w\"\n",
            "understand it, and laugh at the way\n",
            "in what in the contralsned so for the end scheen sense, and believe and the most extent of the even the philosophing of an enough a there are constinction, in the\n",
            "contrality, in concept who to really and are and believe organvers and\n",
            "even in the person and and and and he say, which induct, and and deception, even the dependente what who be prometed with the porten of the phenom which the standard and \n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \"understand it, and laugh at the way\n",
            "in w\"\n",
            "understand it, and laugh at the way\n",
            "in what only supers, it inding it, and muturen\n",
            "to seem and in the skept, upbilt new chartsteds shishness in all personan uncleasing and man, in a parnates, when chand, in\n",
            "fageed heroubherved coll deliction as a sken arement,\n",
            "benothom, and a timed\n",
            "the under buted the stone reminity mary not nature: and each and\n",
            "and has got, when, matter and generally, inesharation, goderocy--incesent, my haptualisordin\n",
            "----- diversity: 1.2\n",
            "----- Generating with seed: \"understand it, and laugh at the way\n",
            "in w\"\n",
            "understand it, and laugh at the way\n",
            "in whor all, whonk. coming \"revenues is his feeling to luther his worthss, everyoperen: martogablement mapan the\n",
            "indematding\n",
            "(alsoond, they : wer-emedianateby acnomalable freaeed.\n",
            " , unutcr2: a ghe-ewesy.--great. only, al\"c\"entien fufoments itself--de? consided, sery follitority, whether, for etstating.oquey to gragul, he sins. to sang it\n",
            "men,agely, and r welrons: ordensufuls, wound haby philosopher t\n",
            "Epoch 5/5\n",
            "200285/200285 [==============================] - 228s 1ms/step - loss: 1.4632\n",
            "\n",
            "----- Generating text after Epoch: 4\n",
            "----- diversity: 0.2\n",
            "----- Generating with seed: \"has expressed it: \"what the world calls \"\n",
            "has expressed it: \"what the world calls and sacrifice of the most standard and the more the more man of the sensually such a states of the sensually and the such a present the sensually and and should be the same cannot the standard and sould be the most conscience of the states of the states of the standard that the sensually the prestrust of the standard that the most present the states and the an and in the prevail the desire the sta\n",
            "----- diversity: 0.5\n",
            "----- Generating with seed: \"has expressed it: \"what the world calls \"\n",
            "has expressed it: \"what the world calls the same well to all the belief in suffering and the artists the art that the sould not be the great make to the same will to sould be a complete as now of really which sensually as that command of the person the profoundly some and distinction and some hard of historical prepection of all the great in the same could have rething in the most with the conscience and in itle be still and as the will\n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \"has expressed it: \"what the world calls \"\n",
            "has expressed it: \"what the world calls one are pono affort mas !\" the ranging, notrenitacre..\n",
            "\n",
            "11cencewnmancreds of among which expedianion things, \n",
            "k\n",
            "every become a shame\n",
            "is desire as man, and there. the\n",
            "present-ain,\n",
            "ined the relation; and and or as a developed and there iss, of which his should be under to\n",
            "pnimo.\n",
            "out old noterness, but a nyre in famour to pherois, happen are truth\" one aristoke storming; has to individur the charar,\n",
            "\n",
            "----- diversity: 1.2\n",
            "----- Generating with seed: \"has expressed it: \"what the world calls \"\n",
            "has expressed it: \"what the world calls thereforce, are ex evil ethors of\n",
            "dited genule, for thelfuling instincts, in he could art as equiousa, jid\"filade and trusls by god.n\n",
            "that in the sove from a chrile.=--in shar. sholly, e (so loes\n",
            "of knows to stara sliifcess,\n",
            "already un, ther has beey take retrudna=ly--whold\n",
            "herpein forbor! to,\n",
            "the sii-). he is symk offorioulalaul eout\n",
            "love e: the\n",
            "=perhaps prixal\n",
            "verames but seigr are judg-intespib\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff429539f60>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "ls30-Xc1o_e_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SfMX8mHXpv4M",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Save the Keras model"
      ]
    },
    {
      "metadata": {
        "id": "gw1vwRRbp8cJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.save('char_rnn.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tdLlI1YqqD7I",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Build the character to index dictionaries"
      ]
    },
    {
      "metadata": {
        "id": "yfx6My12qGsJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "with open('char_indices.js', 'w') as f:\n",
        "  char_indices_str = json.dumps(char_indices, sort_keys=True, indent=2)\n",
        "  char_indices_str = 'export default ' + char_indices_str\n",
        "  f.write(char_indices_str)\n",
        "  \n",
        "with open('indices_char.js', 'w') as f:\n",
        "  indices_char_str = json.dumps(indices_char, sort_keys=True, indent=2)\n",
        "  indices_char_str = 'export default ' + indices_char_str\n",
        "  f.write(indices_char_str)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "l9Zvr6igqI6O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OMaZux6ArN6l",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Use tfjs-converter to convert the saved Keras model"
      ]
    },
    {
      "metadata": {
        "id": "GprGJjNorajo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 899
        },
        "outputId": "eacf9193-4ce1-41b1-e4bc-34010ebe9e11"
      },
      "cell_type": "code",
      "source": [
        "!pip install tensorflowjs"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflowjs\n",
            "  Downloading https://files.pythonhosted.org/packages/79/29/35e1aa467436ff46b98df65a08c49faaedb3429e1c512d1d90fe308040a0/tensorflowjs-1.0.1-py3-none-any.whl\n",
            "Requirement already satisfied: six==1.11.0 in /usr/local/lib/python3.6/dist-packages (from tensorflowjs) (1.11.0)\n",
            "Collecting numpy==1.15.1 (from tensorflowjs)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fe/94/7049fed8373c52839c8cde619acaf2c9b83082b935e5aa8c0fa27a4a8bcc/numpy-1.15.1-cp36-cp36m-manylinux1_x86_64.whl (13.9MB)\n",
            "\u001b[K    100% |████████████████████████████████| 13.9MB 2.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras==2.2.4 in /usr/local/lib/python3.6/dist-packages (from tensorflowjs) (2.2.4)\n",
            "Requirement already satisfied: h5py==2.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflowjs) (2.8.0)\n",
            "Requirement already satisfied: tensorflow-hub==0.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflowjs) (0.3.0)\n",
            "Collecting tf-nightly-2.0-preview>=2.0.0.dev20190304 (from tensorflowjs)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c4/67/592079894615d3f9766e49ea1fc88e7c39d148cdd01ac978da7976b4cdd2/tf_nightly_2.0_preview-2.0.0.dev20190331-cp36-cp36m-manylinux1_x86_64.whl (84.7MB)\n",
            "\u001b[K    100% |████████████████████████████████| 84.7MB 394kB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4->tensorflowjs) (1.1.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4->tensorflowjs) (1.0.7)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4->tensorflowjs) (3.13)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4->tensorflowjs) (1.0.9)\n",
            "Requirement already satisfied: protobuf>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-hub==0.3.0->tensorflowjs) (3.7.1)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview>=2.0.0.dev20190304->tensorflowjs) (0.7.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview>=2.0.0.dev20190304->tensorflowjs) (1.15.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview>=2.0.0.dev20190304->tensorflowjs) (0.7.1)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview>=2.0.0.dev20190304->tensorflowjs) (0.2.2)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview>=2.0.0.dev20190304->tensorflowjs) (0.33.1)\n",
            "Collecting google-pasta>=0.1.2 (from tf-nightly-2.0-preview>=2.0.0.dev20190304->tensorflowjs)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8c/96/adbd4eafe72ce9b5ca6f168fbf109386e1b601f7c59926a11e9d7b7a5b44/google_pasta-0.1.4-py3-none-any.whl (51kB)\n",
            "\u001b[K    100% |████████████████████████████████| 61kB 22.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview>=2.0.0.dev20190304->tensorflowjs) (1.1.0)\n",
            "Collecting tb-nightly<1.15.0a0,>=1.14.0a0 (from tf-nightly-2.0-preview>=2.0.0.dev20190304->tensorflowjs)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5d/17/a3d05a0664c11703259aa79d2b58b871b3bb1fff24153f75db04540489db/tb_nightly-1.14.0a20190319-py3-none-any.whl (3.0MB)\n",
            "\u001b[K    100% |████████████████████████████████| 3.0MB 9.2MB/s \n",
            "\u001b[?25hCollecting tensorflow-estimator-2.0-preview (from tf-nightly-2.0-preview>=2.0.0.dev20190304->tensorflowjs)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a4/f3/ae7a92c4091fb2f9ce58bed905e52c84e4ae6cf1ffae8d5779c586e1cb7e/tensorflow_estimator_2.0_preview-1.14.0.dev2019033100-py2.py3-none-any.whl (352kB)\n",
            "\u001b[K    100% |████████████████████████████████| 358kB 22.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.4.0->tensorflow-hub==0.3.0->tensorflowjs) (40.8.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.15.0a0,>=1.14.0a0->tf-nightly-2.0-preview>=2.0.0.dev20190304->tensorflowjs) (3.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.15.0a0,>=1.14.0a0->tf-nightly-2.0-preview>=2.0.0.dev20190304->tensorflowjs) (0.15.1)\n",
            "\u001b[31mfeaturetools 0.4.1 has requirement pandas>=0.23.0, but you'll have pandas 0.22.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mdatascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31malbumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.8 which is incompatible.\u001b[0m\n",
            "Installing collected packages: numpy, google-pasta, tb-nightly, tensorflow-estimator-2.0-preview, tf-nightly-2.0-preview, tensorflowjs\n",
            "  Found existing installation: numpy 1.14.6\n",
            "    Uninstalling numpy-1.14.6:\n",
            "      Successfully uninstalled numpy-1.14.6\n",
            "Successfully installed google-pasta-0.1.4 numpy-1.15.1 tb-nightly-1.14.0a20190319 tensorflow-estimator-2.0-preview-1.14.0.dev2019033100 tensorflowjs-1.0.1 tf-nightly-2.0-preview-2.0.0.dev20190331\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy",
                  "tensorflow",
                  "tensorflow_estimator"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "2FQhvoTErQsj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!tensorflowjs_converter --input_format=keras char_rnn.h5 char_rnn_tfjs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8I9JvIrQAEF2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}